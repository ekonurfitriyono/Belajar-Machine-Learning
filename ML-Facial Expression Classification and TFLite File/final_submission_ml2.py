# -*- coding: utf-8 -*-
"""Final-Submission-ML2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WMa_7X5lXfU4vZRjAxsTLQx7JVaOXWqr

# **Import Library:**
"""

import os
import tensorflow as tf
import matplotlib.pyplot as plt
import random
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from google.colab import files
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.layers import Input
from tensorflow.keras.regularizers import l2
import pathlib

"""# **Mempersiapkan dataset:**"""

! pip install kaggle

# Commented out IPython magic to ensure Python compatibility.
os.environ['KAGGLE_CONFIG_DIR'] = "/content/Kaggle"
!mkdir /content/Kaggle
# %cd /content/Kaggle

uploaded = files.upload()

!kaggle datasets download -d sujaykapadnis/emotion-recognition-dataset

!unzip \emotion-recognition-dataset.zip && rm emotion-recognition-dataset.zip

dataset_path = '/content/Kaggle/dataset'

os.listdir(dataset_path)

"""# **Menghitung jumlah dataset & Menampilkan Sample Gambar:**"""

categories = os.listdir(dataset_path)
categories_path = []
images_sample = []

# Hitung jumlah total gambar dalam setiap kategori
total_images = 0
for category in categories:
    category_path = os.path.join(dataset_path, category)
    categories_path.append(category_path)
    if os.path.isdir(category_path):
        images = os.listdir(category_path)
        images_sample.append(images[random.randint(1, 100)])
        total_images += len(images)

print(f"Jumlah total gambar dalam dataset: {total_images}")

# Membuat subplot dengan ukuran kolom x baris
fig, axes = plt.subplots(1, 6, figsize=(15, 3))

for i in range(6):
  img = plt.imread(categories_path[i] + "/" + images_sample[i])
  axes[i].imshow(img)
  axes[i].axis('off')
  axes[i].set_title(f'{categories[i]}')

plt.show()

"""# **Membuat Augmentasi:**"""

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    # brightness_range=[0.8, 1.2],  # Variasi tingkat kecerahan
                    # channel_shift_range=50,  # Perubahan acak dalam tingkat warna
                    # zoom_range=0.2,
                    fill_mode = 'nearest',
                    # width_shift_range=0.1,  # Geser gambar secara horizontal hingga 10% lebar gambar
                    # height_shift_range=0.1,  # Geser gambar secara vertikal hingga 10% tinggi gambar
                    validation_split=0.2,) # validation 20%

test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    validation_split=0.2,)

"""# **Membagi Dataset & image preprocessing:**"""

train_generator = train_datagen.flow_from_directory(
        dataset_path,  # direktori data latih
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=64,
        class_mode='categorical',
        shuffle=True,  # Menambahkan parameter shuffle
        seed=42,  # Menambahkan parameter seed
        subset='training')

validation_generator = test_datagen.flow_from_directory(
        dataset_path, # direktori data validasi
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=64,
        class_mode='categorical',
        shuffle=True,  # Menambahkan parameter shuffle
        seed=42,  # Menambahkan parameter seed
        subset='validation')

"""# **Menghitung & Melihat Grafik Distribusi Data Kelas:**

**Menampilkan distribusi data tiap kelas:**
"""

# Mendapatkan daftar kelas dan indeks kelas dari generator aliran data
class_indices = train_generator.class_indices

# Membalikkan mapping untuk mendapatkan nama kelas dari indeks kelas
class_names = list(class_indices.keys())

# Mendapatkan jumlah sampel untuk setiap kelas
class_distribution = train_generator.classes

# Menghitung jumlah sampel untuk setiap kelas
class_count = {class_name: sum(class_distribution == class_index) for class_name, class_index in class_indices.items()}

# Menampilkan distribusi tiap kelas
print("Class Distribution:")
for class_name, count in class_count.items():
    print(f"{class_name}: {count} samples")

"""**Menampilkan Index Kelas:**"""

print("Class Index:")
for class_name, class_index in class_indices.items():
  print(f"{class_name} : {class_index}")

"""**Menampilkan Grafik Distribusi:**"""

import matplotlib.pyplot as plt

# Daftar kelas dan jumlah sampel untuk setiap kelas
class_names = list(class_count.keys())
class_counts = list(class_count.values())

# Membuat plot
plt.figure(figsize=(10, 6))
plt.bar(class_names, class_counts)
plt.xlabel('Class')
plt.ylabel('Number of Samples')
plt.title('Class Distribution')
plt.xticks(rotation=45)
plt.show()

"""# **Menentukan Weight Untuk Setiap Kelas Karena Dataset Tidak Seimbang:**"""

# # Menghitung jumlah sampel untuk setiap kelas
class_count = {class_index: sum(class_distribution == class_index) for class_index in range(len(class_indices))}


# Bobot kelas
class_weights = {class_index: len(class_distribution) / count for class_index, count in class_count.items()}
print("Class Weights:", class_weights)

"""# **Membuat Model:**"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='ELU', input_shape=(150, 150, 3),),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='ELU',),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='ELU',),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3, 3), activation='ELU',),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3, 3), activation='ELU',),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='ELU'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(6, activation='softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics=['accuracy'])

"""# **Pelatihan Model:**"""

threshold = 80 * 1 / 100
print(f"target accuracy : {threshold}")

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > threshold and logs.get('val_accuracy') > threshold):
      print('\nAccuracy diatas 80% tercapai')
      self.model.stop_training = True
callbacks = myCallback()

# Callback untuk mengurangi learning rate jika loss tidak berkurang
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)

# # Callback untuk early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)

steps_per_epoch =  class_distribution
validation_step = validation_generator.classes

# latih model dengan model.fit
history = model.fit(
      train_generator,
      steps_per_epoch=60,
      epochs=100, # tambahkan epochs jika akurasi model belum optimal
      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi
      validation_steps=23,
      class_weight=class_weights,
      callbacks=[
          # early_stopping,
          reduce_lr,
          myCallback()
          ],
      verbose=2)

"""# **Menampilkan Grafik**"""

# melihat grafik training loss dan validation loss

# Gambar grafik loss
plt.plot(history.history['accuracy'], label='Training accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Grafik Loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""# **Membuat & Menyimpan Model**"""

# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadi faceEmotion.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('faceEmotion.tflite')
tflite_model_file.write_bytes(tflite_model)